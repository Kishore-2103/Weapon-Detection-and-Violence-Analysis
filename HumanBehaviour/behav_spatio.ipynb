{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import Conv3D,ConvLSTM2D,Conv3DTranspose\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import cv2 as cv\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagestore=[]\n",
    "video_source_path= \"data_set_final\"\n",
    "fps=2 # skips 1 fps\n",
    "def create_dir(path):\n",
    "\tif not os.path.exists(path):\n",
    "\t\tos.makedirs(path)\n",
    "def remove_images(path):\n",
    "\tfilelist = glob.glob(os.path.join(path, \"*.png\"))\n",
    "\tfor f in filelist:\n",
    "\t\tos.remove(f)\n",
    "\n",
    "def store(image_path):\n",
    "\timg = cv.imread(image_path)\n",
    "\tgray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "\tgray = cv.resize(gray,(227,227),interpolation=cv.INTER_LINEAR_EXACT)\n",
    "\timagestore.append(gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'data_set_final'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m videos \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mlistdir(video_source_path)\n\u001b[0;32m      2\u001b[0m create_dir(video_source_path\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/frames\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m remove_images(video_source_path\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/frames\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'data_set_final'"
     ]
    }
   ],
   "source": [
    "videos = os.listdir(video_source_path)\n",
    "create_dir(video_source_path+'/frames')\n",
    "remove_images(video_source_path+'/frames')\n",
    "framepath = video_source_path+'/frames'\n",
    "for video in videos:\n",
    "\t\tos.system( 'ffmpeg -i {}/{} -r 1/{}  {}/frames/%03d.jpg'.format(video_source_path,video,fps,video_source_path))\n",
    "\t\timages=os.listdir(framepath)\n",
    "\t\tfor image in images:\n",
    "\t\t\timage_path=framepath+ '/'+ image\n",
    "\t\t\tstore(image_path)\n",
    "\t\t\t\n",
    "imagestore=np.array(imagestore)\n",
    "print(imagestore.shape)\n",
    "a,b,c=imagestore.shape\n",
    "imagestore.resize(b,c,a)\n",
    "imagestore=(imagestore-imagestore.mean())/(imagestore.std())\n",
    "imagestore=np.clip(imagestore,0,1)\n",
    "np.save('training.npy',imagestore)\n",
    "os.system('rm -r {}'.format(framepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'training.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# loading training data which is in .npy file\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m X_train\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39mtraining.npy\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(X_train\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      4\u001b[0m frames\u001b[39m=\u001b[39mX_train\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/lib/npyio.py:390\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    388\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 390\u001b[0m     fid \u001b[39m=\u001b[39m stack\u001b[39m.\u001b[39menter_context(\u001b[39mopen\u001b[39;49m(os_fspath(file), \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m    391\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    393\u001b[0m \u001b[39m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'training.npy'"
     ]
    }
   ],
   "source": [
    "# loading training data which is in .npy file\n",
    "X_train=np.load('training.npy')\n",
    "print(X_train.shape)\n",
    "frames=X_train.shape[2]\n",
    "frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'frames' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m frames\u001b[39m=\u001b[39mframes\u001b[39m-\u001b[39mframes\u001b[39m%\u001b[39m\u001b[39m10\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(frames)\n\u001b[1;32m      5\u001b[0m X_train\u001b[39m=\u001b[39mX_train[:,:,:frames]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'frames' is not defined"
     ]
    }
   ],
   "source": [
    "frames=frames-frames%10\n",
    "\n",
    "print(frames)\n",
    "\n",
    "X_train=X_train[:,:,:frames]\n",
    "print(X_train.shape)\n",
    "# reshaping Xtrain to 10 X 1 X 227 X 227\n",
    "\n",
    "X_train=X_train.reshape(-1,227,227,1)\n",
    "print(X_train.shape)\n",
    "\n",
    "# X_train=np.expand_dims(X_train,axis=4)\n",
    "print(X_train.shape)\n",
    "\n",
    "Y_train=X_train.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(X_train[:,:,:\u001b[39m1\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "print(X_train[:,:,:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(X_train\u001b[39m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatio Temporal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadModel():\n",
    "\n",
    "\n",
    "    STModel = Sequential()\n",
    "\n",
    "    STModel.add(Conv3D(filters=128, kernel_size=(11, 11, 1), strides=(4, 4, 1), padding='valid', input_shape=(227, 227, 1,1), activation='relu'))\n",
    "    STModel.add(Conv3D(filters=64, kernel_size=(5, 5, 1), strides=(2, 2, 1), padding='valid', activation='relu'))\n",
    "\n",
    "    STModel.add(ConvLSTM2D(filters=64, kernel_size=(3, 3), strides=1, padding='same', dropout=0.4, recurrent_dropout=0.3, return_sequences=True))\n",
    "    STModel.add(ConvLSTM2D(filters=64, kernel_size=(3, 3), strides=1, return_sequences=True, padding='same', dropout=0.5))\n",
    "\n",
    "    STModel.add(Conv3DTranspose(filters=128,kernel_size=(5,5,1),strides=(2,2,1),padding='valid',activation='relu'))\n",
    "    STModel.add(Conv3DTranspose(filters=1,kernel_size=(11,11,1),strides=(4,4,1),padding='valid',activation='relu'))\n",
    "\n",
    "\n",
    "    STModel.compile(optimizer='SGD', loss='mse', metrics=['accuracy'])\n",
    "\n",
    "    return STModel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-22 02:18:23.899927: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-22 02:18:23.925268: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-22 02:18:23.925665: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-22 02:18:23.927477: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-22 02:18:23.928054: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-22 02:18:23.928394: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-22 02:18:23.928659: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-22 02:18:25.088447: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-22 02:18:25.089760: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-22 02:18:25.090987: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-22 02:18:25.092432: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1585 MB memory:  -> device: 0, name: NVIDIA GeForce MX230, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has been loaded\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 15\u001b[0m\n\u001b[1;32m      8\u001b[0m stopping_point \u001b[39m=\u001b[39m EarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mModel has been loaded\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m model\u001b[39m.\u001b[39mfit(X_train,Y_train,\n\u001b[1;32m     16\u001b[0m \t\t\t\tbatch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m     17\u001b[0m \t\t\t\tepochs\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m     18\u001b[0m \t\t\t\tcallbacks \u001b[39m=\u001b[39m [save,stopping_point]\n\u001b[1;32m     19\u001b[0m \t\t\t\t)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "model=loadModel()\n",
    "\n",
    "save = ModelCheckpoint(\"behaviourtest_3.h5\",\n",
    "\t\t\t\t\t\t\t\t\tmonitor=\"mse\", save_best_only=False)\n",
    "\n",
    "\n",
    "\n",
    "stopping_point = EarlyStopping(monitor='loss', patience=3)\n",
    "\n",
    "\n",
    "print('Model has been loaded')\n",
    "\n",
    "\n",
    "\n",
    "model.fit(X_train,Y_train,\n",
    "\t\t\t\tbatch_size=batch_size,\n",
    "\t\t\t\tepochs=2,\n",
    "\t\t\t\tcallbacks = [save,stopping_point]\n",
    "\t\t\t\t)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "def mean_squared(x1, x2):\n",
    "    difference = x1 - x2\n",
    "    a,b,c,d,e = difference.shape\n",
    "    n_samples = a*b*c*d*e\n",
    "    sq_diff = difference ** 2\n",
    "    Sum = sq_diff.sum()\n",
    "    dist = np.sqrt(Sum)\n",
    "    mean_dist = dist / n_samples\n",
    "    return mean_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=1.16e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Return True if there are abnormal events in Video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_anomly(weights_path,path_to_npy_processed_video_file):\n",
    "    model=load_model(weights_path)\n",
    "\n",
    "    X_test=np.load(path_to_npy_processed_video_file)\n",
    "    print(X_test.shape)\n",
    "    frames=X_test.shape[2]\n",
    "\n",
    "    Anomality  = False\n",
    "\n",
    "    frames=frames-frames%10\n",
    "\n",
    "    X_test=X_test[:,:,:frames]\n",
    "    X_test=X_test.reshape(-1,227,227,1)\n",
    "    # X_test=np.expand_dims(X_test,axis=4)\n",
    "    a_frames = []\n",
    "    for number,bunch in enumerate(X_test):\n",
    "        n_bunch=np.expand_dims(bunch,axis=0)\n",
    "        reconstructed_bunch=model.predict(n_bunch)\n",
    "        loss=mean_squared(n_bunch,reconstructed_bunch)\n",
    "        print(loss,end=\"\\r\")\n",
    "        writer.add_scalar(\"anomality\",loss,number)\n",
    "        writer.flush()\n",
    "        if loss>threshold:\n",
    "            print(\"Anomalous frames @ {}\".format(number),end=\"\\r\")\n",
    "            a_frames.append(number)\n",
    "            Anomality = True\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    if len(a_frames) > 0:\n",
    "        \n",
    "        return Anomality,a_frames\n",
    "    else:\n",
    "        a = []\n",
    "        return Anomality,a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: nvtop: command not found\n"
     ]
    }
   ],
   "source": [
    "! nvtop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at behaviour_2.h5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(predict_anomly(\u001b[39m\"\u001b[39;49m\u001b[39mbehaviour_2.h5\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mf4.npy\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "Cell \u001b[0;32mIn [17], line 2\u001b[0m, in \u001b[0;36mpredict_anomly\u001b[0;34m(weights_path, path_to_npy_processed_video_file)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict_anomly\u001b[39m(weights_path,path_to_npy_processed_video_file):\n\u001b[0;32m----> 2\u001b[0m     model\u001b[39m=\u001b[39mload_model(weights_path)\n\u001b[1;32m      4\u001b[0m     X_test\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mload(path_to_npy_processed_video_file)\n\u001b[1;32m      5\u001b[0m     \u001b[39mprint\u001b[39m(X_test\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/saving/save.py:226\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(filepath_str, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    225\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mexists(filepath_str):\n\u001b[0;32m--> 226\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\n\u001b[1;32m    227\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo file or directory found at \u001b[39m\u001b[39m{\u001b[39;00mfilepath_str\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    228\u001b[0m         )\n\u001b[1;32m    230\u001b[0m     \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39misdir(filepath_str):\n\u001b[1;32m    231\u001b[0m         \u001b[39mreturn\u001b[39;00m saved_model_load\u001b[39m.\u001b[39mload(\n\u001b[1;32m    232\u001b[0m             filepath_str, \u001b[39mcompile\u001b[39m, options\n\u001b[1;32m    233\u001b[0m         )\n",
      "\u001b[0;31mOSError\u001b[0m: No file or directory found at behaviour_2.h5"
     ]
    }
   ],
   "source": [
    "print(predict_anomly(\"behaviour_2.h5\",\"f4.npy\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e918e8484117b157762ade7bce9610f72f52463ccc7808d4eb58acfaf0878cc2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
